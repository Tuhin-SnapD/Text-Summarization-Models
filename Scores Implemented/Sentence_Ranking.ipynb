{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sentence-Ranking\n",
        "**Sentence ranking** is a popular approach for text summarization, where sentences are scored based on their importance and the top-ranked sentences are selected to form the summary. Here are some pros and cons of using sentence ranking for text summarization:\n",
        "\n",
        "## Pros:\n",
        "\n",
        "* It is a simple and intuitive approach that can be easily implemented.\n",
        "* It can handle different types of text, such as news articles, scientific papers, and social media posts.\n",
        "* It can preserve the original structure of the text and provide a coherent summary.\n",
        "* It can be combined with other techniques, such as sentence clustering and sentence compression, to improve the quality of summaries.\n",
        "* It can be evaluated using standard metrics, such as ROUGE and BLEU, which allow for objective comparison with other summarization models.\n",
        "\n",
        "### Cons:\n",
        "\n",
        "* It can be sensitive to the choice of ranking algorithm and feature set, which can affect the quality of the summary.\n",
        "* It may not capture the overall meaning of the text and may miss important information.\n",
        "* It may generate redundant or repetitive information, especially when multiple sentences convey similar information.\n",
        "* It may not handle text with complex syntax or domain-specific terminology well, which can lead to inaccuracies in the summary.\n",
        "* It may not be able to generate summaries that are novel or creative, as it relies on the input text for content.\n",
        "\n",
        "Overall, sentence ranking is a widely used and effective approach for text summarization, but its limitations should be considered when evaluating its performance and potential applications.\n",
        "\n",
        "These are the scores we achieved:\n",
        "\n",
        "      ROUGE Score:\n",
        "      Precision: 0.833\n",
        "      Recall: 0.331\n",
        "      F1-Score: 0.474\n",
        "\n",
        "      BLEU Score: 0.556\n",
        "\n",
        "\n",
        "Here are some research papers that use sentence ranking for text summarization:\n",
        "\n",
        "1. \"TextRank: Bringing Order into Texts\" by R. Mihalcea and P. Tarau. This paper introduces the TextRank algorithm, which is a graph-based approach for sentence ranking and has been widely used for text summarization.\n",
        "\n",
        "2. \"Graph-based Ranking Algorithms for Sentence Extraction, Applied to Text Summarization\" by J. A. Pérez-Carballo and A. García-Serrano. This paper compares the performance of different graph-based algorithms, including TextRank, for extractive text summarization.\n",
        "\n",
        "3. \"Enhancing Sentence Extraction-Based Single-Document Summarization with Supervised Methods\" by D. Das and A. Sarkar. This paper proposes a supervised learning approach for sentence ranking based on features such as sentence length, position, and similarity to the document title.\n",
        "\n",
        "4. \"A Neural Attention Model for Abstractive Sentence Summarization\" by A. Rush et al. This paper uses a neural attention model for abstractive text summarization, where sentences are ranked based on their relevance to the summary and the overall coherence of the text.\n",
        "\n",
        "These papers demonstrate the versatility and effectiveness of sentence ranking for text summarization, and highlight the potential for combining this approach with other techniques to improve the quality of summaries."
      ],
      "metadata": {
        "id": "oQA-i2uwR4Xl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxhlxTeASmuD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d7f6242-b111-429e-f5fa-7366e6b46741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from rouge) (1.15.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "!pip install rouge\n",
        "!pip install nltk\n",
        "from rouge import Rouge \n",
        "import nltk\n",
        "import nltk.translate.bleu_score as bleu\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text =\"\"\"\n",
        " India's Health Ministry has announced that the country's COVID-19 vaccination drive will now be expanded to include people over the age of 60 and those over 45 with co-morbidities. The move is expected to cover an additional 270 million people, making it one of the largest vaccination drives in the world.The decision was taken after a meeting of the National Expert Group on Vaccine Administration for COVID-19 (NEGVAC), which recommended the expansion of the vaccination program. The NEGVAC also suggested that private hospitals may be allowed to administer the vaccine, although the details of this are yet to be finalized.India began its vaccination drive in mid-January, starting with healthcare and frontline workers. Since then, over 13 million doses have been administered across the country. However, the pace of the vaccination drive has been slower than expected, with concerns raised over vaccine hesitancy and logistical challenges.The expansion of the vaccination drive to include the elderly and those with co-morbidities is a major step towards achieving herd immunity and controlling the spread of the virus in India. The Health Ministry has also urged eligible individuals to come forward and get vaccinated at the earliest.India has reported over 11 million cases of COVID-19, making it the second-worst affected country in the world after the United States. The country's daily case count has been declining in recent weeks, but experts have warned that the pandemic is far from over and that precautions need to be maintained.\n",
        "In summary, India's Health Ministry has announced that the country's COVID-19 vaccination drive will be expanded to include people over 60 and those over 45 with co-morbidities, covering an additional 270 million people. The decision was taken after a meeting of the National Expert Group on Vaccine Administration for COVID-19, and is a major step towards achieving herd immunity and controlling the spread of the virus in India.\"\"\""
      ],
      "metadata": {
        "id": "3mRLgqZrTGGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcvob-KKTdDw",
        "outputId": "e84a07f2-67ef-4cb3-f2fb-ff07cf246018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess the text\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "sentences = sent_tokenize(text.lower())\n",
        "words = word_tokenize(text.lower())\n",
        "\n",
        "filtered_words = []\n",
        "for word in words:\n",
        "    if word not in stop_words:\n",
        "        stemmed_word = stemmer.stem(word)\n",
        "        filtered_words.append(stemmed_word)\n",
        "\n",
        "# Calculate the sentence scores\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(sentences)"
      ],
      "metadata": {
        "id": "TXWvQZtxTXtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_scores = []\n",
        "for i in range(len(sentences)):\n",
        "    sentence_score = 0\n",
        "    for word in filtered_words:\n",
        "        if word in vectorizer.get_feature_names():\n",
        "            sentence_score += X[i, vectorizer.vocabulary_[word]]\n",
        "    sentence_scores.append(sentence_score)\n",
        "\n",
        "# Sort the sentences\n",
        "ranked_sentences = sorted(((sentence_scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n",
        "\n",
        "# Select the top N sentences\n",
        "top_n = 3\n",
        "selected_sentences = []\n",
        "for i in range(top_n):\n",
        "    selected_sentences.append(ranked_sentences[i][1])\n"
      ],
      "metadata": {
        "id": "j6ZRp1CVTsAK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f065b9ae-3bf0-453f-dcb6-38cb5851eeb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the summary\n",
        "summary = \" \".join(selected_sentences)\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuUjOtmHTgrZ",
        "outputId": "556e205f-e444-4d2a-8964-96877012a724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in summary, india's health ministry has announced that the country's covid-19 vaccination drive will be expanded to include people over 60 and those over 45 with co-morbidities, covering an additional 270 million people. the decision was taken after a meeting of the national expert group on vaccine administration for covid-19, and is a major step towards achieving herd immunity and controlling the spread of the virus in india. \n",
            " india's health ministry has announced that the country's covid-19 vaccination drive will now be expanded to include people over the age of 60 and those over 45 with co-morbidities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rouge = Rouge()\n",
        "scores = rouge.get_scores(summary, text)\n",
        "print(\"ROUGE Score:\")\n",
        "print(\"Precision: {:.3f}\".format(scores[0]['rouge-1']['p']))\n",
        "print(\"Recall: {:.3f}\".format(scores[0]['rouge-1']['r']))\n",
        "print(\"F1-Score: {:.3f}\".format(scores[0]['rouge-1']['f']))"
      ],
      "metadata": {
        "id": "VRD8sRQLTjLr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9afc655-1998-4eed-cfc1-af310564b5c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE Score:\n",
            "Precision: 0.833\n",
            "Recall: 0.331\n",
            "F1-Score: 0.474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "def summary_to_sentences(summary):\n",
        "    # Split the summary into sentences using the '.' character as a separator\n",
        "    sentences = summary.split('.')\n",
        "    \n",
        "    # Convert each sentence into a list of words\n",
        "    sentence_lists = [sentence.split() for sentence in sentences]\n",
        "    \n",
        "    return sentence_lists\n",
        "\n",
        "def paragraph_to_wordlist(paragraph):\n",
        "    # Split the paragraph into words using whitespace as a separator\n",
        "    words = paragraph.split()\n",
        "    return words\n",
        "\n",
        "reference_paragraph = text\n",
        "reference_summary = summary_to_sentences(reference_paragraph)\n",
        "predicted_paragraph = summary\n",
        "predicted_summary = paragraph_to_wordlist(predicted_paragraph)\n",
        "\n",
        "score = sentence_bleu(reference_summary, predicted_summary)\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7wQs-Kvd-ib",
        "outputId": "416c31ad-abb9-43f8-f3d2-b00a35bc7489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5559999307354189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"BLEU Score: {:.3f}\".format(score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zOk9qa6ffsv",
        "outputId": "f73b4821-f1cb-4381-99a0-2e0abb2f561d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 0.556\n"
          ]
        }
      ]
    }
  ]
}